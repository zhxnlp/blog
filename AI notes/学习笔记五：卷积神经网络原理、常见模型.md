@[toc]
>参考动手深度学习第六章[《卷积神经网络》](https://zh-v2.d2l.ai/chapter_convolutional-neural-networks/index.html)、第七章[《现代卷积神经网络》](https://zh-v2.d2l.ai/chapter_convolutional-modern/index.html)、[cs231n卷积神经网络](https://cs231n.github.io/convolutional-networks/)、[《深度学习在图像处理中的应用》](https://blog.csdn.net/qq_37541097/article/details/103482003)
## 一、CNN模型原理

### 1.1 卷积原理
&#8195;&#8195;图像可以用像素点来表示，存储为一个三维矩阵（height×width×channels）。黑白图片channels=1，即每个像素点只有灰度值（0或255，分别表示黑色和白色）。彩色图像channels=3，每个像素点由RGB三原色组成，对应一个三维向量，值域[0，255]。<font color='deeppink'>图像具有平移不变性和旋转不变性</font >。即对图像的平移或者轻微旋转不改变其类别。
1. DNN进行图像处理的局限性
	
	* **不抗平移、旋转**：图像的平移或旋转会导致特征矩阵的剧烈变化，影响分类效果。
	* **计算量大**：图像像素高，直接用DNN处理（全连接层）计算量大、耗时长，且参数过多，需要大量训练样本。

2. 人类认识图片的原理：人类关注图像的**几何形状**及其相对位置，也就是图像中更抽象的轮廓信息，而非具体像素值。所以好的图像处理模型模型需要对平移、旋转、笔迹变化等不敏感且参数较少。

3. 卷积原理：卷积神经网络利用了输入由图像组成这一事实，它们以更合理的方式约束架构
	* **感受野与卷积核**：CNN通过卷积核对图像的局部区域（也叫感受野）进行特征提取。
	* **卷积运算**：感受野的像素值与卷积核按位相乘并求和，加入偏置后通过激活函数（如ReLU）生成特征图（Feature Map）。
	* **特征图**：输出的是感受野与卷积核匹配程度的强度值，表示该区域特征，而非像素值。与卷积核形状差异过大的感受野输出为0（经过Relu激活），所以卷积核也叫滤波器Filter。

4. 卷积的特点：
	* **多通道卷积**：多通道图像经过卷积核卷积后结果为单通道图像（多通道分别卷积后加和得到最终结果），需多个卷积核才能保持多通道输出。<font color='red'>同一个通道的卷积结果是一类特征（同一个卷积核计算的结果）</font>
	* **卷积核为可学习参数**：卷积核的参数通过模型训练自动获得。
	* **多尺寸卷积核**：CNN使用不同尺寸的卷积核提取不同级别的图像特征，以减少参数。
	

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/257b17e922424fe7bd30370dcd824d2a.gif#pic_center)
	

5. 卷积应用

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/151c074a8253c87ed6a60e1cfa42cb89.png#pic_center =600x)




### 1.2 池化原理
&#8195;&#8195;池化（Pooling）是卷积神经网络（CNN）中的一种操作，通常用于缩减特征图的空间维度，即减少数据的大小，同时保留图像的关键特征。池化操作通过对图像的局部区域进行汇总或降采样，能够降低运算量和参数量，同时增强模型对图像的平移、旋转等几何变化的不敏感性。下面是一个2×2，步幅为2的最大池化示意图：
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e9ed1827a80b2a1a28bce50e29c7b778.png#pic_center)
1.  池化层的作用
	- **缩减图像尺寸**：减少特征图的尺寸，降低计算量和参数量。
	- **抗平移旋转**：池化对轻微的平移和旋转不敏感，缓解卷积层对位置变化的敏感性。
	- **增大感受野，减少计算量**：缩减特征图后，使后续卷积操作的感受野增大，提取更宏观的特征。
	- **减少信息冗余**：消除相邻感受野间的冗余信息，提高效率（相邻感受野形状差异不大）。

2. 池化的特点
	- **无需学习参数**：池化操作只需设定池化层大小和标准（最大池化、均值池化等），无需学习参数。
	- **最大池化 vs 均值池化**：
	  - 最大池化提取特征能力强，但易受噪声干扰。
	  - 均值池化稳定，抗噪性强。
	  - 两种池化混用时，推荐前层使用最大池化，提取特征；后层使用均值池化，减少尺寸、抗平移。 若先用均值池化，特征可能被平均掉，难以恢复；因此先提取特征，再进行去噪。
	- **独立通道处理**：池化在各个通道上独立进行。
	- **步长设定**：步长通常与感受野尺寸相同，以避免池化时的交集。

3. 场景应用
	1. **人脸识别**（公司打卡系统）：需要高精度提取五官特征，适合使用**最大池化**。
	2. **人脸检测**（是否有面部）：只需大致轮廓，适合使用**均值池化**。



### 1.3 Flatten
&#8195;&#8195;在卷积和池化操作后，CNN输出的是一个**多通道的二维特征图**，例如一个尺寸为7×7×10的矩阵。这个矩阵可以理解为包含10个7×7的二维特征图，每个特征图对应于图像的某些特征（如边缘、纹理等）。

&#8195;&#8195;然而，在分类任务中（如图像分类），最终的**Softmax层**只能处理一个**一维向量**，因为它的作用是输出各个类别的概率分布。所以在连接到Softmax之前，必须将这些多通道的二维特征转换为一个一维向量，这就是**Flatten（拉平）操作**的作用。

>Flatten没有学习参数，仅是将多通道的二维矩阵展平为一个一维向量，便于后续分类。

### 1.4 卷积池化总结

1. **特征提取与多层结构**：
   - CNN通过**不同卷积核**提取图像中的特定形状特征，配合**池化操作**缩减尺寸、稳定特征。
   - 低级特征经过多次卷积和池化逐步提取出更高级的复杂特征。多层卷积-池化的堆叠使CNN能够识别复杂的图像模式。

2. **图像预处理**：
   - **图像尺寸统一**：CNN只能处理固定尺寸的图像，实际中需将输入图像调整为相同尺寸。
   - **归一化处理**：为了防止数值溢出和梯度问题，输入图像的像素值会归一化到[0,1]。

3. **特征归一化与通道独立性**：
CNN中，每个通道对应一种特征（通过同一个卷积核计算的结果），所以可以对每个通道单独进行批归一化，分别计算每个通道的均值和方差，确保训练稳定。

4. **参数简化：卷积 vs 全连接**：
   - 对于28×28×1的图像，若采用**全连接**并保持尺寸不变，参数量为28×28×1×28×28×1=614656个。
   - 若采用**3×3卷积核**并保持尺寸不变，参数量显著减少，仅为**28×28×1×3×3**。可以理解为CNN通过让每个隐藏层神经元仅与相邻的**9个神经元**连接，且各个位置参数共享，极大减少了参数量。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/98c6816465924519a25d1d338b982d9d.png#pic_center)
   

&#8195;&#8195;CNN通过**权重共享**与 **局部感受野（剪枝）** 简化了全连接的DNN结构，避免了冗余计算，减少了参数量，提高了模型的计算效率和性能。


## 二、卷积计算
一个常见的CNN例子如下图：
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/7b69d4e7fac84dac952b88ef76120ca5.png#pic_center)

### 2.1 卷积计算
#### 2.1.1 二维卷积（2D Convolution）

&#8195;&#8195;**二维卷积**主要用于处理单通道的图像，例如灰度图像。每个卷积核与图像的局部区域进行点积运算，并生成一个二维特征图，其操作步骤为：

1. **选择一个局部区域**：将卷积核放置在输入图像的某个局部区域，大小与卷积核一致。
2. **点积操作**：将卷积核与图像对应位置的像素值逐元素相乘，再将乘积结果求和。
3. **滑动卷积核**：按照设定的步幅，在整个图像上滑动卷积核，重复上述步骤，最终生成一个特征图。
4. **填充（padding）**：如果要保持输出尺寸与输入尺寸一致，可使用适当的填充方式，如 "same" padding。




![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/493929e53cf1a56ec15c21c494912816.png#pic_center =600x)
经过卷积后的图像尺寸公式为： $$W = \frac{N - K + 2P}{S} + 1$$ 其中，$N$为图像尺寸，$K$为卷积核尺寸，$P$为边缘填充，$S$为步幅。若要保持卷积后尺寸不变，要求输出尺寸 $W = N$，因此有： $$N = \frac{N - K + 2P}{S} + 1$$ 当步幅 $S = 1$ 时，得到： $$P = \frac{K - 1}{2}$$
这意味着对于一个 $K \times K$ 的卷积核，通常需要在图像边缘每一侧填充 $\frac{K - 1}{2}$ 个像素。例如，对于 $3 \times 3$ 的卷积核，需要填充1个像素（$P = 1$），这样卷积后的图像尺寸保持不变。
#### 2.1.2  三维卷积（3D Convolution）
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d0eaefdf4c734056802955dc86c0e5ce.png#pic_center)


&#8195;&#8195;**三维卷积**用于处理多通道图像，例如RGB彩色图像，每个通道的图像可以看作一个二维矩阵，整体图像为三维矩阵。


* **输入图像**：大小为 $N \times N \times C$，其中 $C$ 为通道数，例如RGB图像的 $C = 3$。
* **卷积核**：大小为 $K \times K \times C$。
* **输出特征图**：卷积后的图像仍为二维特征图，大小为 $(N - K + 2P) / S + 1$。

操作步骤：

1. **分通道卷积**：卷积核对每个通道的二维矩阵分别进行卷积，得到不同通道的特征图。
2. **通道相加**：将每个通道的卷积结果相加，得到最终的二维特征图。




#### 2.1.3  多个三维卷积核

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/fc7c1fb022cb4643ba3b42dbb0ce8c2e.png#pic_center)
&#8195;&#8195;使用一个多通道卷积核对多通道图像卷积，结果仍是单通道图像（多通道分别卷积后加和得到最终结果）。要想保持多通道结果，就得使用多个卷积核。<font color='red'>同一个通道的卷积结果是一类特征（同一个卷积核计算的结果）</font>。

&#8195;&#8195;为了提取图像的不同特征，通常会使用**多个三维卷积核**。每个卷积核提取不同的特征，并生成一个对应的二维特征图。最终的输出是多个二维特征图的集合，组成了一个**多通道的特征图**。


* **输入图像**：大小为 $N \times N \times C$。
* **多个卷积核**：设有 $F$ 个卷积核，每个卷积核的大小为 $K \times K \times C$。
* **输出特征图**：经过卷积后，得到 $F$ 个二维特征图，输出为大小为 $(N - K + 2P) / S + 1 \times F$。

操作步骤：

1. **每个卷积核进行三维卷积**：每个三维卷积核对输入图像的所有通道进行卷积，生成一个二维特征图。
2. **输出多个特征图**：对每个卷积核执行上述操作，得到 $F$ 个二维特征图，将它们组合形成最终的输出。

&#8195;&#8195;假设输入图像大小为 $5 \times 5 \times 3$（RGB图像），有 $4$ 个 $3 \times 3 \times 3$ 的卷积核。每个卷积核会生成一个 $3 \times 3$ 的二维特征图，最终输出 $4$ 个 $3 \times 3$ 特征图，形成一个 $3 \times 3 \times 4$ 的多通道输出。

#### 2. 1.4  卷积计算的总结

* **二维卷积**：用于处理单通道图像，卷积核与局部区域相乘并求和，生成特征图。
* **三维卷积**：用于处理多通道图像（如RGB图像），卷积核对每个通道分别进行卷积，最终相加生成特征图。
* **多个三维卷积核**：用于提取不同的特征，通过多个卷积核并行操作，输出多个二维特征图，形成多通道的输出。



在实践中，卷积操作需要根据任务的复杂性选择适当的卷积核数量和大小：

* **卷积核的大小**：通常选择 $3 \times 3$、$5 \times 5$ 等小尺寸卷积核，以保证计算效率和特征提取能力。
* **卷积层的深度**：多层卷积可以提取越来越高级的特征，适用于复杂的图像识别任务。
* **边缘填充（padding）**：常用 "same" padding 保持输出图像尺寸不变，有助于保留边缘信息。

>图片卷积中, 卷积核一般为奇数，这是因为：
>- **容易控制卷积输出的尺寸**：单数尺寸卷积核可以更容易配合padding操作保持输出图像尺寸一致。例如，在使用 $3×3$ 卷积核并设置步幅 $S=1$ 和填充 $P=1$ 时，卷积操作可以确保输入图像的尺寸保持不变。如果是偶数尺寸的卷积核，会出现需要填充0.5的情况。
>- **中心点的对称性**：单数尺寸的卷积核有一个明确的中心点，保证核的左右、上下对称。这种对称性在特征提取中非常重要，有助于保持平移不变性（卷积时，中心像素始终处于同一参考点，卷积操作不会丢失对称信息。）
#### 2.1.5 Python实现

以下是一个简单的Python代码，用于演示二维卷积的计算：

```python
import numpy as np
from scipy.signal import convolve2d

# 输入图像（5x5矩阵）
image = np.array([
    [1, 2, 0, 1, 3],
    [4, 5, 6, 7, 8],
    [1, 0, 1, 2, 3],
    [4, 2, 3, 4, 5],
    [1, 1, 0, 1, 2]
])

# 卷积核（3x3矩阵）
kernel = np.array([
    [1, 0, 1],
    [0, 1, 0],
    [1, 0, 1]
])

# 进行卷积操作
output = convolve2d(image, kernel, mode='valid')

print(output)
```

该代码会对一个 $5 \times 5$ 的图像进行 $3 \times 3$ 的卷积，输出 $3 \times 3$ 的特征图。






###  2.2 CNN前向传播算法
输入：1个图片样本，CNN模型的层数L和所有隐藏层的类型，对于卷积层，要定义卷积核的大小K，卷积核子矩阵的维度F，填充大小P，步幅S。对于池化层，要定义池化区域大小k和池化标准（MAX或Average），对于全连接层，要定义全连接层的激活函数（输出层除外）和各层的神经元个数。

　　　　输出：CNN模型的输出$a^L$

　　　　&#8195;&#8195;1) 根据输入层的填充大小P，填充原始图片的边缘，得到输入张量$a^1$。

　　　　&#8195;&#8195;2）初始化所有隐藏层的参数$W,b$　　

　　　　&#8195;&#8195;3）for $l$=2 to $L-1$（层数$l$）:

&#8195;&#8195;&#8195;&#8195;a) 如果第$l$层是<font color='deeppink'>卷积层</font>,则输出为（*表示卷积，而不是矩阵乘法）
$$ a^l= ReLU(z^l) = ReLU(a^{l-1}*W^l +b^l)$$　　
&#8195;&#8195;&#8195;&#8195;（这里要定义卷积核个数，卷积核中每个子矩阵大小，填充padding（以下简称P）和填充padding（以下简称P））
 　　　　b) 如果第$l$层是<font color='deeppink'>池化层</font>,则输出为：$$a^l= pool(a^{l-1})$$
 　　　　 需要定义池化大小和池化标准,池化层没有激活函数

　　　　　　&#8195;&#8195;&#8195;&#8195;c) 如果第$l$层是<font color='deeppink'>全连接层</font>,则输出为：$$ a^l= \sigma(z^l) = \sigma(W^la^{l-1} +b^l)$$

　　　　&#8195;&#8195;4)对于<font color='deeppink'>输出层第L层</font>: $$ a^L= softmax(z^L) = softmax(W^La^{L-1} +b^L)$$
### 2.3 CNN反向传播算法
>参考[《卷积神经网络(CNN)》](https://blog.csdn.net/qq_56591814/article/details/124603386?spm=1001.2014.3001.5501)

## 三、深入卷积层
### 3.1 1×1卷积
1. 卷积的本质是有效提取相邻像素间的相关特征，而1×1卷积显然没有此作用。
2. <font color='red'> 1×1卷积不识别空间模式，只融合通道。并常用来改变通道数，降低运算量和参数量。同时增加一次非线性变化，提升网络拟合能力。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e6882e09ae71abc35ed3d028bb965e7b.png#pic_center)
- 输出中的每个元素都是从输入图像中同一位置的元素的线性组合。我们可以将1×1卷积层看作是在
每个像素位置应用的全连接层，以$c_ i$个输入值转换为$c_o$ 个输出值。因为这仍然是1个卷积层，所以跨像素的权重是一致的。
- 对于一个$28×28×f_{1}$的图像，进行$f_{2}个1×1$卷积操作，得到$28×28×f_{2}$的图像，且参数量仅有$f_{1}×f_{2}$（忽略偏置）。
	- $f_{1}>f_{2}$时起到降维的作用，降低其它卷积操作的运算量。但是降维太厉害会丢失很多信息。
	-  $f_{1}<f_{2}$时起到升维作用（增加通道数），可以让后续卷积层提取更加丰富的特征
- 所以可以先用1×1卷积改变通道数，再进行后续卷积操作，这个是Depth wise提出的。
### 3.2 VGGnet：使用块、小尺寸卷积效果好
>[《动手深度学习——VGG》](https://zh-v2.d2l.ai/chapter_convolutional-modern/vgg.html)
- 卷积的尺寸决定卷积的视野，越大则提取的特征越宏观。但是大尺寸卷积，参数量和运算量都很大，而<font color='deeppink'>多个小尺寸卷积可以达到相同的效果，且参数量更小。还可以多次进行激活操作，提高拟合能力。</font>例如：
一个5×5卷积参数量25，可以替换成两个3×3卷积。，参数量为18。每个3×3卷积可以替换成3×1卷积加1×3卷积，参数量为12。
- 使用卷积块来设计神经网络。使用块的想法首先出现在牛津大学的视觉几何组（visualgeometry group）的VGG网络中。通过使用循环和子程序，可以很容易地在任何现代深度学习框架的代码中实现这些重复的架构。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/700d8b2168b31c0ebf3ed317cc0ff15f.png#pic_center)
### 3.3 NiN
AlexNet、VGG等卷积之后都接了两个全连接层，而全连接层参数量是很大的，也容易造成过拟合。
- 卷积层参数：$c_{i}\times c_{o}\times k^{2}$
- n类全连接层参数：$c\times m_{w}\times m_{h}\times n$
- LeNet 16x5x5x120 = 48k
AlexNet 256x5x5x4096 = 26M
VGG 512x7x7x4096 = 102M
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/4d345754a5c42402de4f1229a123bc6c.png#pic_center)

### 3.4 inception宽度卷积核和GoogLeNet
GoogLeNet重点是解决了什么样⼤⼩的卷积核最合适的问题（使⽤不同⼤⼩的卷积核组合是有利的）
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/5329258d5081cf5042f44f1d9b966cb0.png#pic_center)

实际CNN识别中，会遇到识别物体尺寸不一的情况。不同尺寸的物体需要不同尺寸的卷积核来提取特征。如果增加网络深度来处理，会造成：
- 训练集不够大，则过拟合
- 深层网络容易梯度消失，模型难以优化
- 简单堆叠较大的卷积层浪费计算资源

<font color='deeppink'>为了使卷积层适应不同的物体尺寸，一般会在同一层网络中并列使用多种尺寸的卷积，以定位不同尺寸的物体。此时增加了网络宽度，而不会增加其深度。

2016年google的inception模型首先提出，结构如下：
>图片参考：[《深入解读GoogLeNet网络结构（附代码实现）》](https://blog.csdn.net/qq_37555071/article/details/108214680)

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/6ff06bfc60fb085bb2488a9052e80a61.png#pic_center)



- 使用四条不同超参数的卷积层和池化层抽取不同的信息，最后结果进行级联（按通道拼在一起）。池化层是抗位置敏感性。
- 多个卷积核级联造成通道数过多，所以可以在卷积前、3×3池化后分别进行1×1卷积进行降维，同时提高网络非线性程度。
- 最终输出和输入图像尺寸相同，但是通道数可以不一样。
- 与单个3x3或5x5卷积层相比，初始块具有更少的参数和更低的计算复杂度
不同功能混合（多样的功能类）
卷积核计算高效（良好的泛化）
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/619ff7175c72eeb37d72799792c4cc72.png#pic_center)

多个inception堆叠就是GoogLeNet:

这样会有一个问题：	<font color='deeppink'>网络太深造成梯度消失，前面的层基本就没有什么信息了（梯度消失学不到）。所以中间层引入两个辅助分类器，并配以辅助损失函数。防止前层网络信息丢失。</font >具体地：

- 三个黄色和椭圆模块是做三次分类。即在3.6.9层inception时输出做分类。
- 三个分类器的任务完全一样，$loss=w_{1}loss_{1}+ w_{2}loss_{2}
+w_{3}loss_{3}$。$w_{3}$的系数应该高一些，具体权重可以查。辅助分类器只用来训练，不用于推断
- 训练时三个分类器一起训练，使用的时候只用最后一层。最后一个inception使用全局平均池化（没有要求最后一个inception输出通道等于类别数）
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/f6128193479155f2de8877c750c770aa.png#pic_center)


GoogleNet知识点：
1. inception
2. 深层网络可以从中间抽取loss来训练，防止过拟合。
3. 启发：网络太深，涉及梯度消失时，都可以这样搞：中间层可以抽出loss来一起学习。（shortcut也可以，一个道理，可能还好一点，比较方便）。
4. 借鉴了NiN使用大量1×1卷积替代全连接层，最后用了全局平均汇聚层。
5. 后续有一系列的改进，到V3、V4精度才真正提上来，并一直在被使用。但是太复杂了，其实不怎么受欢迎。（实际使用GoogleNet结构最好不要大改，通道数可以倍增倍减这样动动。）

GoogleNet：
- 第一个红色框住的模块叫stem（根源），就是传统的卷积。
- 后面九个模块都是inception，再过一个全连接层，最后过softmax进行分类。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/9b4fb597c78ed710c9cb7e39b057d373.png#pic_center)GluonCV 模型“动物园”https://gluon-cv.mxnet.io/model_zoo/classification.html
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/26a722730a9bafa2ff99abe6f0f321b3.png#pic_center)

### 3.4 Depth wise和Pointwise降低运算量
- 传统卷积：一个卷积核卷积图像的所有通道，参数过多，运算量大。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/b29196c8701bfd8acee1db0bf5f32f50.png#pic_center)
运算量（忽略偏置）：$28*28*128*3*3*256=231211008$
参数量（忽略偏置）：$128*3*3*256=294912$
- Depth wise卷积：一个卷积核只卷积一个通道。输出图像通道数和输入时不变。缺点是每个通道独立卷积运算，没有利用同一位置上不同通道的信息
- Pointwise卷积：使用多个1×1标准卷积，将Depth wise卷积结果的各通道特征加权求和，得到新的特征图
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/9351eeceb10afa9530f76a53cff686b4.png#pic_center)
运算量（忽略偏置）：$28*28*128*3*3+28*28*128*256=26593280$
参数量（忽略偏置）：$3*3*128+128*256=33920$
### 3.5 SENet、CBAM特征通道加权卷积
#### 3.5.1 SENet
>可参考[《CNN卷积神经网络之SENet及代码》](https://blog.csdn.net/qq_41917697/article/details/114100031)
SENet：卷积操作中，每个通道对应一类特征。而不同特征对最终任务结果贡献是不一样的，所以考虑调整各通道的权重。
1. SE模块，对各通道中所有数值进行全局平均，此操作称为Squeeze。比如28×28×128的图像，操作后得到128×1的向量。
2. 此向量输入全连接网络，经过sigmoid输出128维向量，每个维度值域为（0,1），表示各个通道的权重
3. 在正常卷积中改为各通道加权求和，得到最终结果
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/6cbb85373f76cb6a6715dc0fd21173cf.png#pic_center)

- Squeeze建立channel间的依赖关系；Excitation重新校准特征。二者结合强调有用特征抑制无用特征
- 能有效提升模型性能，提高准确率。几乎可以无脑添加到backbone中。根据论文，SE block应该加在Inception block之后，ResNet网络应该加在shortcut之前，将前后对应的通道数对应上即可
#### 3.5.2 CBAM
>参考[《CBAM重点干货和流程详解及Pytorch实现》](https://blog.csdn.net/qq_36584673/article/details/116088055)
>
除了通道权重，CBAM还考虑空间权重，即：图像中心区域比周围区域更重要，由此设置不同位置的空间权重。CBAM将空间注意力和通道注意力结合起来。

Channel attention module：
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/5836c1cc25f8c2b8b716ebc63f4819a9.png#pic_center)
- 输入特征图F，经过两个并行的最大值池化和平均池化将C×H×W的特征图变成C×1×1的大小
- 经过一个共享神经网络Shared MLP(Conv/Linear，ReLU，Conv/Linear)，压缩通道数C/r (reduction=16)，再扩张回C，得到两个激活后的结果。
- 最后将二者相加再接一个sigmoid得到权重channel_out，再加权求和。

<font color='deeppink'>此步骤与SENet不同之处是加了一个并行的最大值池化，提取到的高层特征更全面，更丰富。

Channel attention module：

将上一步得到的结果通过最大值池化和平均池化分成两个大小为H×W×1的张量，然后通过Concat操作将二者堆叠在一起(C为2)，再通过卷积操作将通道变为1同时保证H和W不变，经过一个sigmoid得到spatial_out，最后spatial_out乘上一步的输入变回C×H×W，完成空间注意力操作

总结：
- 实验表明：通道注意力在空间注意力之前效果更好
- 加入CBAM模块不一定会给网络带来性能上的提升，受自身网络还有数据等其他因素影响，甚至会下降。如果网络模型的泛化能力已经很强，而你的数据集不是benchmarks而是自己采集的数据集的话，不建议加入CBAM模块。要根据自己的数据、网络等因素综合考量。
### 3.6 inception几个改进版
google对inception进行改造，出现了inception1→inception2→inception3→Xception→inception4→inception ResNetV1→inception →ResNetV2。
#### 3.6.1 Inception2
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/09ea72e33afdee1001e699d4a68bfee6.png#pic_center)
<font color='deeppink'>变种A是基础版的5×5改成两个3×3，B是3×3拆成两个，C是拆成的两个并联。

对卷积核进行了几种改造。但是设计思想都是：
1.大量应用1×1卷积核和n×1卷积核（1×3和3×1）
2.大量应用小卷积核（没有超过3乘3的）
3.并联卷积
#### 3.6.2 Inception3
最大贡献：标签平滑防止过拟合

- 对于逻辑回归来说，单个样本$loss=-ylogy’-(1-y)log(1-y’)$。y’∈（0,1）是一个闭区间,预测值y’只能无限逼近0和1，但是永远取不到0或1。即单个样本没有极小值。
- 这样在拟合的时候随着梯度下降，y’不断向0或1逼近，w会不断增大。而如果标签y=1做平滑改成y=0.97，y’就可以取到这个值，w就不会无限增大，所以避免了过拟合。
- 也可以看做对标签适当注入噪声防止过拟合。（LR可以看做二分类的softmax，所以此处也适用）
- 加正则项主要是让模型在测试集上的效果尽可能和训练集效果一样好，标签平滑让模本本身有一个好的性能（防止标签打错等噪声）。
#### 3.6.3 Xception、inception4
- Xception：3×3正常卷积变成Depth wise（上一节讲过）
- inception4是改变了stem
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/0f7276367ceef5ec55ad65cd44867dee.png#pic_center)
#### 3.6.4 inception ResNetV1&2
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/97ce4afcf67520d260f1f521c82dd6be.png#pic_center)
inception ResNetV1&2最主要思想就是与shortcut结合。inception模块的输出和模块输入直接按位相加。即对应channel对应位置的元素相加。这样就要求输出的channel和尺寸要和输出的一致。而一般不池化尺寸可以不变，channel数通过最后一层的1×1卷积核来调整。
	至于中间的细节，右侧的构造为啥是这样的，都是试验碰出来的，没必要纠结。


### 3.7 Resnet
>参考[《CNN卷积神经网络之ResNeXt》](https://blog.csdn.net/qq_41917697/article/details/115905056)、[《残差网络resnet》](https://zh-v2.d2l.ai/chapter_convolutional-modern/resnet.html)

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/78ad6c1894bc5b952566386dba92d53f.png#pic_center)

&#8195;&#8195;对于非嵌套函数类，较复杂（由较大区域表示）的函数类不能保证更接近“真”函数（ $(f^*$) ）。这种现象在嵌套函数类中不会发生。因此，<font color='red'> 只有当较复杂的函数类包含较小的函数类时，我们才能确保提升它们的性能。 </font>
&#8195;&#8195;对于深度神经⽹络，如果我们能将新添加的层训练成恒等映射（identity function）f(x) = x，新模型和原模型将同样有效。同时，由于新模型可能得出更优的解来拟合训练数据集，因此添加层似乎更容易降低训练误差。针对这一问题，何恺明等人提出了残差往络（ResNet）[He et al., 2016a]。它在2015年的ImageNet图像识别挑战赛夺魁，并深刻影响了后来的深度神经网络的设计。<font color='red'> 残差网络的核心思想是：每个附加层都应该更容易地包含原始函数作为其元素之一。 </font>

&#8195;&#8195;Resnet也是借鉴shortcut思想，因为网络太深必然会碰到梯度消失的问题。然后就是一堆小卷积核，每两层抄一次近道是试验出来的效果。抄近道就必须保持前后的channel数一致。
>7.6. 残差网络（ResNet）答疑
> 1. 为啥f(x)=x+g(x)可以保证模型至少不会变坏？g（x）难道不会学的比较差反而影响f（x）效果吗？
> &#8195;&#8195;这是因为g(x)也是训练出来的，如果模型发现只用f（x）=x效果就很好，而加上g（x）对loss的下降几乎没什么贡献，那么梯度反传的时候，g（x）部分几乎拿不到梯度，权重就很小，这样g（x）对整个模型几乎没什么影响。所以这就是为啥resnet加深时通常不会让模型效果变差。
> 2. 为啥这个网络叫残差网络？残差概念体现在哪？
> 以resnet51举例，可以认为是先训练一个resnet18的基础模型来拟合，剩下的与真实值的误差（残差）用剩下的层进一步拟合（先训练下层的基础block，剩下没训练好的上层继续fit。这就是残差Residual的由来）
> 3. 训练acc是永远大于测试acc吗？是不是意味着图片识别永远达不到100%识别
>测试acc是有可能大于训练acc的，这是因为训练时构造数据可能会加入一些误差，而测试集没有。模型识别率也不会达到100%，因为ImageNet数据集本身标识就有2%-5% 的错误。所以追求100%没必要。（一般不能假设数据集100%分类正确，因为可能有些样本人都很难分）


**残差块（residual block）：**
&#8195;&#8195;<font color='red'>虚线是添加的层，直接添加层会更改原特征类 </font>
&#8195;&#8195;假设我们的原始输入为x，模型希望学出的理想映射为f(x)。下图左图虚线框中的部分需要直接拟合出该映射f(x)，而右侧虚线框中的部分则需要拟合出残差映射f(x) − x。
&#8195;&#8195;残差映射在现实中往往更容易优化。以本节开头提到的恒等映射作为我们希望学出的理想映射f(x)，我们只需将下图中右图虚线框内上方的加权运算（如仿射）的权重和偏置参数设成0，那么f(x)即为恒等映射。实际中，当理想映射f(x)极接近于恒等映射时，残差映射也易于捕捉恒等映射的细微波动。在残差块中，输入可通过跨层数据线路更快地向前传播。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/0d5087c9c12d2d5cf0257d54e179361a.png#pic_center)
resnet中残差块有两种：（use_1x1conv=True/False）
1. 步幅为2 ，高宽减半，通道数增加。所以shortcut连接部分会加一个1×1卷积层改变通道数
2. 步幅为1，高宽不变
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/f33e84364600f273b25c8f718856817e.png#pic_center)
残差块代码实现：
```python
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l

class Residual(nn.Module):  #@save
    def __init__(self, input_channels, num_channels,
                 use_1x1conv=False, strides=1):
        super().__init__()
        self.conv1 = nn.Conv2d(input_channels, num_channels,
                               kernel_size=3, padding=1, stride=strides)
        self.conv2 = nn.Conv2d(num_channels, num_channels,
                               kernel_size=3, padding=1)
        if use_1x1conv:
            self.conv3 = nn.Conv2d(input_channels, num_channels,
                                   kernel_size=1, stride=strides)
        else:
            self.conv3 = None
        self.bn1 = nn.BatchNorm2d(num_channels)
        self.bn2 = nn.BatchNorm2d(num_channels)#每个bn都有自己的参数要学习，所以需要定义两个

    def forward(self, X):
        Y = F.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))
        if self.conv3:
            X = self.conv3(X)
        Y += X
        return F.relu(Y)
```

resnet18：类似VGG和GoogLeNet，但是替换了resnet块。一般用resnet34或者50，很少上100，除非刷榜。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/8c06eea11c22f811c2e642d860b7b379.png#pic_center)
Resnet18代码：
```python
b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
                   nn.BatchNorm2d(64), nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))

def resnet_block(input_channels, num_channels, num_residuals,
                 first_block=False):
    blk = []
    for i in range(num_residuals):
        if i == 0 and not first_block:
            blk.append(Residual(input_channels, num_channels,
                                use_1x1conv=True, strides=2))
        else:
            blk.append(Residual(num_channels, num_channels))
    return blk

b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))
b3 = nn.Sequential(*resnet_block(64, 128, 2))
b4 = nn.Sequential(*resnet_block(128, 256, 2))
b5 = nn.Sequential(*resnet_block(256, 512, 2))#resnet_block是一个列表，*表示全部展开

net = nn.Sequential(b1, b2, b3, b4, b5,
                    nn.AdaptiveAvgPool2d((1,1)),
                    nn.Flatten(), nn.Linear(512, 10))
```
### 3.8 Resnext
>论文：[Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431)
 PyTorch代码：https://github.com/miraclewkf/ResNeXt-PyTorch
 参考文章[《ResNeXt算法详解》](https://blog.csdn.net/u014380165/article/details/71667916)、讲解视频[《ResNeXt网络结构》](https://www.bilibili.com/video/BV1Ap4y1p71v/?vd_source=21011151235423b801d3f3ae98b91e94)
#### 3.8.1 模型效果
&#8195;&#8195;作者提出 ResNeXt 的主要原因在于：传统的要提高模型的准确率，都是加深或加宽网络，但是随着超参数数量的增加（比如channels数，filter size等等），网络设计的难度和计算开销也会增加。因此本文提出的 <font color='red'>ResNeXt 结构可以在不增加参数复杂度的前提下提高准确率，同时还减少了超参数的数量。 </font >（得益于子模块的拓扑结构一样）。
&#8195;&#8195;**对比 ResNeXt 101和另外几种网络，在不同入网尺寸下，错误更少，效果都更好。**
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/2ee212efa577b6bb6014265ca343302e.png#pic_center)
- 左图：统计resnet50和resnext50在ImageNet上top1的错误率。蓝色、橙色实线分别是二者在验证集上的错误率
- 右图 ：统计resnet101和resnext101在ImageNet上top1的错误率


![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/cbc67fb44af4bd3261e23e244432b0bb.png#pic_center)
#### 3.8.2 Group Conv组卷积
>&#8195;&#8195;下图假设卷积核大小为k×k，输入矩阵channel数为$C_{in}$，卷积核个数为n（输出矩阵channel数）。组卷积分成g个组（group）
>
&#8195;&#8195;如下图所示，将输入矩阵的channel划分为两个组（蓝色和绿色），然后对每个组分别进行卷积操作，最后将其在channel维度拼接，得到最终卷积结果。这样算下来，组卷积参数个数是常规卷积的1/g。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/a3b9d1a95cb26790152c052a9ce23eba.png#pic_center)
#### 3.8.3 模型结构
ResNeXt和ResNet的最本质的区别在于其中使用新的block替换后者中的block：
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/59851b29df5cb3054fafd017b5f9e834.png#pic_center)
下面的block模块使用了分组卷积，在数学计算上完全等价：
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/f77f4a64198afc8a1b2b6e3f69e00114.png#pic_center)
- 图a：等价于图b。输入channel=4先进行32个分支的1×1的卷积再相加，等价于32个分支先concat拼接成channel=128的输入，再经过256个1×1的卷积。下面举例说明：
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/4a388c8dd53d3b9e2cc302454fa05914.png#pic_center)
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/91af913ca5de033172ee0ce34282d502.png#pic_center)

- 图b：可等价转为图c，各层对应。具体的，将输入分为32个分支，每个分支都经过4个1×1卷积核4个3×3的卷积，所以可以合并为图c的结构。
- 图c：
	- 首先通过128个1×1卷积核将channel从256降为128
	- 使用g=32的分组卷积， 卷积核大小3×3，个数还是128，这一层输入输出通道数不变
	- 通过256个1×1卷积核将channel从128升为256，和原来不变
	- 卷积输出结果和输入相加

根据模块c，就可以搭建ResNeXt50：
- 32×4d中，32表示group数，也就是conv中的C的值；4表示每个组中卷积核的个数为4
- 可以看出，ResNeXt50和ResNet50网络结构一样，原有block替换成新的block就行。
- 为啥g=32？作者通过实验发现随着g的增大，错误率越来越低，最后选了32。
- **作者还说过，一般残差block如果结果少于三层是没有多大意义的**。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/149f260ff1a95e3f386f6e5d4853edf7.png#pic_center)

&#8195;&#8195;全文看下来，作者的核心创新点就在于提出了 aggregrated transformations，用一种平行堆叠相同拓扑结构的blocks代替原来 ResNet 的三层卷积的block，在不明显增加参数量级的情况下提升了模型的准确率，同时由于拓扑结构相同，超参数也减少了，便于模型移植。

### 3.9 树叶分类竞赛
图片分类竞赛地址：https://www.kaggle.com/c/classify-leaves。176类树叶，每类至少50张图片。公榜私榜数据集五五分。


