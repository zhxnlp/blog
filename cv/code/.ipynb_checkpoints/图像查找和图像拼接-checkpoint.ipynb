{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像查找\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T13:05:59.652751Z",
     "start_time": "2021-12-10T13:04:44.363302Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 97.580536  86.01131 ]]\n",
      "\n",
      " [[ 92.22693  435.28137 ]]\n",
      "\n",
      " [[471.19598  435.6533  ]]\n",
      "\n",
      " [[465.97693   85.17234 ]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 打开图片\n",
    "img1 = cv2.imread('opencv_search.png')\n",
    "img2 = cv2.imread('opencv_orig.png')\n",
    "\n",
    "# 灰度化\n",
    "g1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "g2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#创建特征检测器\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# 计算特征点和描述子\n",
    "kp1, des1 = sift.detectAndCompute(g1, None)\n",
    "kp2, des2 = sift.detectAndCompute(g2, None)\n",
    "\n",
    "# 创建特征匹配器\n",
    "index_params = dict(algorithm=1, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# 对描述子进行特征匹配\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "# print(matches)\n",
    "goods = []\n",
    "for (m, n) in matches:\n",
    "    # 阈值一般设0.7到0.8之间.\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        goods.append(m)\n",
    "        \n",
    "# print(goods)\n",
    "# 通过goods把特征点找到\n",
    "# 因为计算单应性矩阵要求最少4个点\n",
    "if len(goods) >= 4:\n",
    "    src_points = np.float32([kp1[m.queryIdx].pt for m in goods]).reshape(-1, 1, 2)\n",
    "    dst_points = np.float32([kp2[m.trainIdx].pt for m in goods]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # 根据匹配上的关键点去计算单应性矩阵.\n",
    "    H, _ = cv2.findHomography(src_points, dst_points, cv2.RANSAC, 5)\n",
    "    # 通过单应性矩阵, 计算小图(img1)小图在大图中的对应位置.\n",
    "    h, w = img1.shape[:2]\n",
    "    pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "    # warpPerspective是对图片进行透视变换的.\n",
    "#     cv2.warpPerspective()\n",
    "    dst = cv2.perspectiveTransform(pts, H)\n",
    "    print(dst)\n",
    "    # 在大图中, 把dst画出来\n",
    "    cv2.polylines(img2, [np.int32(dst)], True, (0, 0, 255), 2)\n",
    "else:\n",
    "    print('not enough point number to compute homography matrix')\n",
    "    exit()\n",
    "\n",
    "# 画出匹配的特征点\n",
    "ret = cv2.drawMatchesKnn(img1, kp1, img2, kp2, [goods], None)\n",
    "cv2.imshow('ret', ret)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T09:08:06.737984Z",
     "start_time": "2022-04-18T09:07:59.650947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(962, 743, 3)\n",
      "(962, 743)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#打开两个文件\n",
    "img1 = cv2.imread('./map1.png')\n",
    "img2 = cv2.imread('./map2.png')\n",
    "print(img1.shape)\n",
    "#灰度化\n",
    "g1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "g2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(img1.shape[:2])\n",
    "#他建SIFT特征检测器\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "#计算描述子与特征点\n",
    "kp1, des1 = sift.detectAndCompute(g1, None)\n",
    "kp2, des2 = sift.detectAndCompute(g2, None)\n",
    "\n",
    "#创建匹配器\n",
    "index_params = dict(algorithm = 1, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "#对描述子进行匹配计算\n",
    "matchs = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "good = []\n",
    "for i, (m, n) in enumerate(matchs):\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "if len(good) >= 10: \n",
    "    srcPts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2) \n",
    "    dstPts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    # 查找单应性矩阵\n",
    "    M,mask=cv2.findHomography(srcPts,dstPts,cv2.RANSAC,5.0)\n",
    "    #利用M矩阵的逆求解视角和IMG1特征匹配的点的IMG2图 并且IMG1没有像素\n",
    "    warpImg = cv2.warpPerspective(img2, np.linalg.inv(M), (img1.shape[1]+img2.shape[1], img2.shape[0]+6))#后面广播的时候高度会缺失6个像素\n",
    "    direct=warpImg.copy()#深拷贝一份\n",
    "    direct[0:img1.shape[0], 0:img1.shape[1]]=img1#将左边IMG1的部分重新赋值\n",
    "\n",
    "ret = cv2.drawMatchesKnn(img1, kp1, img2, kp2, [good], None) \n",
    "\n",
    "# 处理中间黑线问题. \n",
    "# 经过仔细观察, 中间的黑线是左图自带的. 黑线在第743列的位置, 我们把这一列删掉\n",
    "direct3 = np.hstack((direct[:, :742].copy(), direct[:, 744:].copy()))\n",
    "# 然后再对局部做一个高斯模糊. \n",
    "dst = cv2.GaussianBlur(direct3[:, 740:747], (5, 5), sigmaX=0)\n",
    "# 替换\n",
    "direct3[:, 740:747] = dst\n",
    "\n",
    "cv2.imshow('result', direct3) \n",
    "cv2.imshow('ret',ret)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 图像拼接的思路.\n",
    "1. 读图片\n",
    "2. 灰度化处理\n",
    "3. 计算各自的特征点和描述子\n",
    "4. 匹配特征. \n",
    "5. 根据匹配到的特征, 计算单应性矩阵.\n",
    "6. 对图片进行透视变换.\n",
    "7. 创建一个大图. \n",
    "8, 放入两张图. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T06:41:18.766579Z",
     "start_time": "2022-04-18T06:41:02.947904Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   0.          0.      ]]\n",
      "\n",
      " [[   0.        479.      ]]\n",
      "\n",
      " [[ 639.        479.      ]]\n",
      "\n",
      " [[ 639.          0.      ]]\n",
      "\n",
      " [[-889.6273   -306.8511  ]]\n",
      "\n",
      " [[-906.8617    703.6594  ]]\n",
      "\n",
      " [[ 269.37122   430.22433 ]]\n",
      "\n",
      " [[ 289.39008    21.082191]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# 读图片\n",
    "img1 = cv2.imread('left_01.png')\n",
    "img2 = cv2.imread('right_01.png')\n",
    "\n",
    "# 把两张图的尺寸设置成同样大小\n",
    "img1 = cv2.resize(img1, (640, 480))\n",
    "img2 = cv2.resize(img2, (640, 480))\n",
    "\n",
    "# 灰度化处理\n",
    "g1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "g2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 创建sift对象\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "\n",
    "# 创建特征匹配器\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "goods = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        goods.append(m)\n",
    "        \n",
    "if len(goods) >= 4:\n",
    "    # 根据DMatch对象拿到各自的特征点\n",
    "    src_points = np.float32([kp1[m.queryIdx].pt for m in goods]).reshape(-1, 1, 2)\n",
    "    dst_points = np.float32([kp2[m.trainIdx].pt for m in goods]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # 计算单应性矩阵\n",
    "    # 第一个对变成第二个图的视角, 计算出来的单应性矩阵.\n",
    "    H, _ = cv2.findHomography(src_points, dst_points, cv2.RANSAC, 5)\n",
    "else:\n",
    "    print('not enough point number to compute homography matrix')\n",
    "    exit()\n",
    "    \n",
    "\n",
    "# 获取原始图的高和宽\n",
    "h1, w1 = img1.shape[:2]\n",
    "h2, w2 = img2.shape[:2]\n",
    "img1_pts = np.float32([[0, 0], [0, h1 - 1], [w1 - 1, h1 - 1], [w1 -1, 0]]).reshape(-1, 1, 2)\n",
    "img2_pts = np.float32([[0, 0], [0, h2 - 1], [w2 - 1, h2 - 1], [w2 -1, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "# 根据前面计算出来的H, 计算img1的四个角变换之后的坐标\n",
    "img1_transform = cv2.perspectiveTransform(img1_pts, H)\n",
    "# print(img1_pts)\n",
    "# print(img1_transform)\n",
    "result_pts = np.concatenate((img2_pts, img1_transform), axis=0)\n",
    "print(result_pts)\n",
    "# print(result_pts.min(axis=0))\n",
    "[x_min, y_min] = np.int32(result_pts.min(axis=0).ravel() - 1)\n",
    "[x_max, y_max] = np.int32(result_pts.max(axis=0).ravel() + 1)\n",
    "\n",
    "# 手动构造平移矩阵\n",
    "move_matrix = np.array([[1, 0, -x_min],[0, 1, -y_min], [0, 0, 1]])\n",
    "# 对img1进行平移后透视变换\n",
    "result_img = cv2.warpPerspective(img1, move_matrix.dot(H), (x_max -x_min, y_max - y_min))\n",
    "# 如果不平移, img1很大一部分都在显示窗口外面, 我们看不到.\n",
    "# result_img = cv2.warpPerspective(img1, H, (x_max -x_min, y_max - y_min))\n",
    "# 把img2放进来\n",
    "# img2_window = result_img[-y_min: -y_min + h2,-x_min: -x_min + w2]\n",
    "# print(img2_window.shape)\n",
    "# cv2.imshow('img2_window', img2_window) \n",
    "result_img[-y_min: -y_min + h2,-x_min: -x_min + w2] = img2\n",
    "\n",
    "\n",
    "cv2.imshow('result_img', result_img)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 虚拟计算器项目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:00:10.734906Z",
     "start_time": "2021-12-15T14:00:10.723935Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建button类\n",
    "class Button:\n",
    "    def __init__(self, pos, width, height, value):\n",
    "        self.pos = pos\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.value = value\n",
    "        \n",
    "    def draw(self, img):\n",
    "        # 绘制一个计算器的小格子\n",
    "        # 先画一个实心的灰色矩形\n",
    "        cv2.rectangle(img, (self.pos[0], self.pos[1]), (self.pos[0] + self.width, self.pos[1] + self.height), (225, 225, 225), -1)\n",
    "        # 再画矩形的边框\n",
    "        cv2.rectangle(img, (self.pos[0], self.pos[1]), (self.pos[0] + self.width, self.pos[1] + self.height), (0, 0, 0), 3)\n",
    "        cv2.putText(img, self.value, (self.pos[0] + 30, self.pos[1] + 70), cv2.FONT_HERSHEY_PLAIN, 2, (50, 50, 50), 2)\n",
    "        \n",
    "    def check_click(self, x, y):\n",
    "        if self.pos[0] < x < self.pos[0] +self.width and self.pos[1] < y < self.pos[1] + self.height:\n",
    "            cv2.rectangle(img, (self.pos[0] + 3, self.pos[1] + 3), \n",
    "                         (self.pos[0] + self.width -3, self.pos[1]+self.height -3),\n",
    "                        (255, 255, 255), -1)\n",
    "            cv2.putText(img, self.value, (self.pos[0]+25, self.pos[1] + 80), cv2.FONT_HERSHEY_PLAIN, 5, (0, 0, 0), 5)\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:09:58.563633Z",
     "start_time": "2021-12-15T14:09:16.009253Z"
    }
   },
   "outputs": [],
   "source": [
    "# 从打开摄像头, 显示每一帧图片开始\n",
    "import numpy as np\n",
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import time\n",
    "\n",
    "# 需要安装cvzone和mediapipe\n",
    "# pip install cvzone mediapipe -i https://pypi.douban.com/simple\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# 设置窗口大小.\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "button_values = [['7', '8', '9', '*'],\n",
    "                 ['4', '5', '6', '-'],\n",
    "                 ['1', '2', '3', '+'],\n",
    "                 ['0', '/', '.', '=']]\n",
    "\n",
    "button_list = []\n",
    "for x in range(4):\n",
    "    for y in range(4):\n",
    "        x_pos = x * 100 + 800\n",
    "        y_pos = y * 100 + 150\n",
    "        button = Button((x_pos, y_pos), 100, 100, button_values[y][x])\n",
    "        button_list.append(button)\n",
    "\n",
    "# 创建hand detector\n",
    "detector = HandDetector(maxHands=1, detectionCon=0.8)\n",
    "\n",
    "my_equation = ''\n",
    "\n",
    "while True:\n",
    "    flag, img = cap.read()\n",
    "    # 摄像头显示的画面和真实画面反掉了.\n",
    "    img = cv2.flip(img, 1)\n",
    "    if flag:\n",
    "        for button in button_list:\n",
    "            button.draw(img)\n",
    "            \n",
    "        # 创建显示结果的窗口\n",
    "        cv2.rectangle(img, (800, 70), (800 + 400, 70 + 100), (225, 225, 225), -1)\n",
    "        cv2.rectangle(img, (800, 70), (800 + 400, 70 + 100), (50, 50, 50), 3)\n",
    "        \n",
    "        # 检测手\n",
    "        hands, img = detector.findHands(img, flipType=False)\n",
    "#         print(hands)\n",
    "        if hands:\n",
    "            # 取出食指和中值的点, 计算两者的距离\n",
    "            lmlist = hands[0]['lmList']\n",
    "            length, _, img = detector.findDistance(lmlist[8], lmlist[12], img)\n",
    "#             print(length, _, img)\n",
    "#             print(length)\n",
    "            # 取出手指的坐标\n",
    "            x, y = lmlist[8]\n",
    "        \n",
    "        # 根据食指和中指之间的距离, 如果小于50, 我们认为是进行了点击操作.\n",
    "        if length < 50:\n",
    "            for i, button in enumerate(button_list):\n",
    "                if button.check_click(x, y):\n",
    "                    # 说明是一个正确点击. 应该要把点中的数字显示在窗口上. \n",
    "                    my_value = button_values[int(i % 4)][int(i / 4)]\n",
    "                    # 如果是'=', 说明要计算了.\n",
    "                    if my_value == '=':\n",
    "                        my_equation = str(eval(my_equation))\n",
    "                    else:\n",
    "                        # 字符串的拼接\n",
    "                        my_equation += my_value\n",
    "                        time.sleep(0.1)\n",
    "        \n",
    "        cv2.putText(img, my_equation, (810, 130), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 0), 3)\n",
    "        cv2.imshow('img', img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('c'):\n",
    "            # 清空输出框\n",
    "            my_equation = ''\n",
    "    else:\n",
    "        print('摄像头打开失败')\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 课后思考:\n",
    "1. 如何解决手被计算器边缘挤压的问题.\n",
    "2. 如何解决点击数字重复出现问题.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T13:56:43.126673Z",
     "start_time": "2021-12-15T13:56:43.116700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '9 + 3'\n",
    "eval(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
